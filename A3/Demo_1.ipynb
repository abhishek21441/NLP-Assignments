{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oYbU1S1mgN7Y"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from sentence_transformers import SentenceTransformer\n",
        "model2 = SentenceTransformer('all-MiniLM-L6-v2')\n",
        "state_dict = torch.load(\"BERT_STS_1C.pth\")\n",
        "\n",
        "# Set the loaded state dictionary to the model\n",
        "model2.load_state_dict(state_dict)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "\n",
        "\n",
        "# Initialize an empty dictionary\n",
        "test_data_dict = {}\n",
        "test_data_dict[\"Sentence_1\"]=[]\n",
        "test_data_dict[\"Sentence_2\"]=[]\n",
        "\n",
        "# Open the CSV file\n",
        "with open('sample_test.csv', mode='r') as file:\n",
        "    # Create a CSV reader object\n",
        "    reader = csv.reader(file)\n",
        "    reader=list(reader)\n",
        "    # Iterate over each row in the CSV file\n",
        "    for i in range(1,len(reader)):\n",
        "        row=reader[i]\n",
        "        if len(row)==1:\n",
        "            row=row[0].split('\\t')\n",
        "        else:\n",
        "            row=''.join(row).split('\\t')\n",
        "        #print(row)\n",
        "        test_data_dict[\"Sentence_1\"].append(row[1])\n",
        "        test_data_dict[\"Sentence_2\"].append(row[2])\n",
        "\n",
        "import torch\n",
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from scipy.stats import pearsonr\n",
        "from torch.nn import CosineSimilarity\n",
        "predicted_scores = []\n",
        "with torch.no_grad():\n",
        "      texts_a, texts_b = test_data_dict[\"Sentence_1\"], test_data_dict[\"Sentence_2\"]\n",
        "      embeddings_a = model2.encode(texts_a, convert_to_tensor=True)\n",
        "      embeddings_b = model2.encode(texts_b, convert_to_tensor=True)\n",
        "      cosine_similarity = CosineSimilarity(dim=1)\n",
        "      predicted_scores.extend(cosine_similarity(embeddings_a,embeddings_b))\n",
        "\n",
        "predicted_scores = [float(value.to(\"cpu\"))*5 for value in predicted_scores]\n",
        "test_data_dict[\"Scores\"] = predicted_scores"
      ],
      "metadata": {
        "id": "BNqhgMIagUBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(test_data_dict).to_csv(\"sample_demo.csv\",sep = \"\\t\")"
      ],
      "metadata": {
        "id": "-Pok-Op7gdor"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}